# 计划表

## Stage 1（废除）

​		解决多摄像头数据（非深度）输入，生成人体姿态检测的三维模型（使用MediaPipe开源模型）。

1. 配置MediaPipe环境，实现视频、图片数据的导入与识别。
2. 学习输出坐标的数据格式，探索如何将两个2D图片数据合成为3D数据。
3. 学习3D模型的输出方式。
4. 学习OpenCV基础，实现两个摄像头数据的同步输入。
5. 面向对象的开发方式，编写用于多摄像头数据识别的类。

## Stage 2

1. 硬件环境搭建，安装“Ubuntu”操作系统，安装“向日葵”远程操作。

2. 学习一个3D姿态检测的demo程序（细致学习——数据输入、训练过程、结果输出）

   **学哪个？？**

3. 在已搭建的硬件环境中，完成一次上述网络的训练，预测。

4. 学习Kinect摄像头的使用，获取**目标的**数据输入格式。

## Stage 3

1. 成功配置Ubuntu操作系统无线网络（技巧：使用USB共享；使用系统Setting配置无线网络参数）。
2. 安装显卡驱动，完成Kinect摄像头在Ubuntu系统下的基础配置，并进行系统备份。
3. 将Openpose系统部署在Ubuntu系统上，实现简单Demo程序的运行，实时预测Kinect输入图像的人体位姿。
4. 学习openpose的API，掌握目标数据的输出。

## Stage 4

1. 使用标定板，得到相机与世界坐标系的单应性矩阵，从而得到三维坐标。
2. 使用深度数据对三维坐标进行修正。（如何修正是个问题？）
3. 对两台相机得出的三维坐标数据进行数据融合，融合体现在对关键点的跟踪上。（两台相机主要是避免遮挡问题）
4. 基于模型：从关键点坐标连接构建人体骨架（杆）的刚性模型，该刚性模型在运动过程中保持刚性。刚性模型的动力学参数通过一些简单的运动进行估计得到（雅可比矩阵？关节末端运动速度与轴的转动？）关节末端的速度也就是关键点，可以识别得到。
5. 点的跟踪也许可以使用卡尔曼滤波实现。

## Stage 5

1. 熟悉openpose代码，熟悉k4a库
2. 熟悉3D重建的基本理论逻辑：
   - 获取相机外参、内参、畸变参数
   - 如何在获取到图片中的对应点后，根据相机参数重建3d坐标
